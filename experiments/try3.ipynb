{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx, to_scipy_sparse_matrix\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.linalg import pinv\n",
    "from math import inf\n",
    "from numba import jit, int64\n",
    "\n",
    "def choose_edge_to_add(x, edge_index, degrees):\n",
    "    # chooses edge (u, v) to add which minimizes y[u]*y[v]\n",
    "    n = x.size\n",
    "    m = edge_index.shape[1]\n",
    "    y = x / ((degrees + 1) ** 0.5)\n",
    "    products = np.outer(y, y)\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        products[u, v] = inf\n",
    "    for i in range(n):\n",
    "        products[i, i] = inf\n",
    "    smallest_product = np.argmin(products)\n",
    "    return (smallest_product % n, smallest_product // n)\n",
    "\n",
    "def compute_degrees(edge_index, num_nodes=None):\n",
    "    # returns array of degrees of all nodes\n",
    "    if num_nodes is None:\n",
    "        num_nodes = np.max(edge_index) + 1\n",
    "    degrees = np.zeros(num_nodes)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        degrees[edge_index[0, i]] += 1\n",
    "    return degrees\n",
    "\n",
    "def add_edge(edge_index, u, v):\n",
    "    new_edge = np.array([[u, v],[v, u]])\n",
    "    return np.concatenate((edge_index, new_edge), axis=1)\n",
    "\n",
    "def adj_matrix_multiply(edge_index, x):\n",
    "    # given an edge_index, computes Ax, where A is the corresponding adjacency matrix\n",
    "    n = x.size\n",
    "    y = np.zeros(n)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        y[u] += x[v]\n",
    "    return y\n",
    "\n",
    "def compute_spectral_gap(edge_index, x):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\ty = adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\tfor i in range(n):\n",
    "\t\tif x[i] > 1e-9:\n",
    "\t\t\treturn 1 - y[i]/x[i]\n",
    "\treturn 0.\n",
    "\n",
    "def _edge_rewire(edge_index, edge_type, x=None, num_iterations=50, initial_power_iters=50):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tif x is None:\n",
    "\t\tx = 2 * np.random.random(n) - 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\tfor i in range(initial_power_iters):\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\tfor I in range(num_iterations):\n",
    "\t\ti, j = choose_edge_to_add(x, edge_index, degrees=degrees)\n",
    "\t\tedge_index = add_edge(edge_index, i, j)\n",
    "\t\tdegrees[i] += 1\n",
    "\t\tdegrees[j] += 1\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\treturn edge_index, edge_type, x\n",
    "\n",
    "def edge_rewire(edge_index, x=None, edge_type=None, num_iterations=50, initial_power_iters=5):\n",
    "    m = edge_index.shape[1]\n",
    "    n = np.max(edge_index) + 1\n",
    "    if x is None:\n",
    "        x = 2 * np.random.random(n) - 1\n",
    "    if edge_type is None:\n",
    "        edge_type = np.zeros(m, dtype=np.int64)\n",
    "    return _edge_rewire(edge_index, edge_type=edge_type, x=x, num_iterations=num_iterations, initial_power_iters=initial_power_iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Create a new graph with the rewired edges\\nnew_G = nx.Graph()\\nnew_G.add_nodes_from(range(data.num_nodes))\\nnew_edges = list(zip(new_edge_index[0], new_edge_index[1]))\\nnew_G.add_edges_from(new_edges)\\n\\n# Print some statistics\\nprint(f\"Original number of edges: {G.number_of_edges()}\")\\nprint(f\"New number of edges: {new_G.number_of_edges()}\")\\nprint(f\"Number of added edges: {new_G.number_of_edges() - G.number_of_edges()}\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Apply the FOSR method\n",
    "def apply_fosr(edge_index, rewire_fraction=0.1, min_iterations=10, max_iterations=1000):\n",
    "    edge_type = np.zeros(edge_index.shape[1], dtype=np.int64)\n",
    "    n = np.max(edge_index) + 1\n",
    "    x = 2 * np.random.random(n) - 1\n",
    "    \n",
    "    # Calculate num_iterations based on the number of edges and rewire_fraction\n",
    "    num_edges = edge_index.shape[1]\n",
    "    num_iterations = int(num_edges * rewire_fraction)\n",
    "    \n",
    "    # Ensure num_iterations is within a reasonable range\n",
    "    num_iterations = max(min_iterations, min(num_iterations, max_iterations))\n",
    "    \n",
    "    print(f\"Number of iterations for FOSR: {num_iterations}\")\n",
    "    \n",
    "    new_edge_index, new_edge_type, _ = edge_rewire(\n",
    "        edge_index, \n",
    "        x=x, \n",
    "        edge_type=edge_type, \n",
    "        num_iterations=num_iterations, \n",
    "        initial_power_iters=5\n",
    "    )\n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "# Function to apply FOSR to any dataset\n",
    "def apply_fosr_to_dataset(dataset, rewire_fraction=0.1, min_iterations=10, max_iterations=1000):\n",
    "    data = dataset[0]\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    edge_index = np.array(list(G.edges())).T\n",
    "    \n",
    "    new_edge_index, new_edge_type = apply_fosr(edge_index, rewire_fraction, min_iterations, max_iterations)\n",
    "    \n",
    "    new_G = nx.Graph()\n",
    "    new_G.add_nodes_from(range(data.num_nodes))\n",
    "    new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "    new_G.add_edges_from(new_edges)\n",
    "    \n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "#new_edge_index, new_edge_type = apply_fosr_to_dataset(dataset)\n",
    "'''\n",
    "# Create a new graph with the rewired edges\n",
    "new_G = nx.Graph()\n",
    "new_G.add_nodes_from(range(data.num_nodes))\n",
    "new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "new_G.add_edges_from(new_edges)\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Original number of edges: {G.number_of_edges()}\")\n",
    "print(f\"New number of edges: {new_G.number_of_edges()}\")\n",
    "print(f\"Number of added edges: {new_G.number_of_edges() - G.number_of_edges()}\")'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_commute_time(graph):\n",
    "    \"\"\"\n",
    "    Compute the commute time for each pair of nodes in a graph.\n",
    "    :param graph: A NetworkX graph object.\n",
    "    :return: Commute time matrix (numpy array).\n",
    "    \"\"\"\n",
    "    # Convert graph to adjacency matrix (scipy sparse format)\n",
    "    adj_matrix = nx.adjacency_matrix(graph)\n",
    "    \n",
    "    # Compute degree matrix\n",
    "    degrees = np.array(adj_matrix.sum(axis=1)).flatten()\n",
    "    D = np.diag(degrees)\n",
    "    \n",
    "    # Compute Laplacian matrix L = D - A\n",
    "    L = D - adj_matrix.toarray()\n",
    "    \n",
    "    # Compute the pseudoinverse of the Laplacian\n",
    "    L_pseudo = pinv(L)\n",
    "    \n",
    "    # Compute commute time between all pairs of nodes\n",
    "    num_nodes = L.shape[0]\n",
    "    commute_time = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            commute_time[i, j] = L_pseudo[i, i] + L_pseudo[j, j] - 2 * L_pseudo[i, j]\n",
    "    \n",
    "    return commute_time\n",
    "\n",
    "\n",
    "def aggregate_commute_times(graph):\n",
    "    \"\"\"\n",
    "    Aggregate the commute times for a single graph.\n",
    "    :param graph: A NetworkX graph object.\n",
    "    :return: Average commute time across the graph.\n",
    "    \"\"\"\n",
    "    commute_times = compute_commute_time(graph)\n",
    "    \n",
    "    # Get upper triangular part of the commute time matrix (since it's symmetric)\n",
    "    upper_triangle_indices = np.triu_indices_from(commute_times, k=1)\n",
    "    commute_times_upper = commute_times[upper_triangle_indices]\n",
    "    \n",
    "    # Return average commute time\n",
    "    return np.mean(commute_times_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_edge_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m new_G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mGraph()\n\u001b[1;32m     13\u001b[0m new_G\u001b[38;5;241m.\u001b[39madd_nodes_from(\u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mnum_nodes))\n\u001b[0;32m---> 14\u001b[0m new_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(new_edge_index[\u001b[38;5;241m0\u001b[39m], new_edge_index[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     15\u001b[0m new_G\u001b[38;5;241m.\u001b[39madd_edges_from(new_edges)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Print some statistics\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_edge_index' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the Cora dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# Convert to NetworkX graph\n",
    "G = to_networkx(data, to_undirected=True)\n",
    "\n",
    "# Get edge index from the graph\n",
    "edge_index = np.array(list(G.edges())).T\n",
    "\n",
    "# Create a new graph with the rewired edges\n",
    "new_G = nx.Graph()\n",
    "new_G.add_nodes_from(range(data.num_nodes))\n",
    "new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "new_G.add_edges_from(new_edges)\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Original number of edges: {G.number_of_edges()}\")\n",
    "print(f\"New number of edges: {new_G.number_of_edges()}\")\n",
    "print(f\"Number of added edges: {new_G.number_of_edges() - G.number_of_edges()}\")\n",
    "\n",
    "\n",
    "\n",
    "new_edge_index, new_edge_type = apply_fosr_to_dataset(dataset)\n",
    "\n",
    "# Create a new graph with the rewired edges\n",
    "G_fosr = nx.Graph()\n",
    "G_fosr.add_nodes_from(range(data.num_nodes))\n",
    "new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "G_fosr.add_edges_from(new_edges)\n",
    "\n",
    "# Calculate aggregate commute times for both graphs\n",
    "agg_commute_time_original = aggregate_commute_times(G_original)\n",
    "agg_commute_time_fosr = aggregate_commute_times(G_fosr)\n",
    "\n",
    "print(f\"Original Graph - Aggregate Commute Time: {agg_commute_time_original:.4f}\")\n",
    "print(f\"FOSR-modified Graph - Aggregate Commute Time: {agg_commute_time_fosr:.4f}\")\n",
    "\n",
    "# Calculate the percentage change in aggregate commute time\n",
    "percent_change = ((agg_commute_time_fosr - agg_commute_time_original) / agg_commute_time_original) * 100\n",
    "\n",
    "print(f\"Percentage change in Aggregate Commute Time: {percent_change:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations for FOSR: 527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/zkb1xvsx6s1gy5dwtqm90krc0000gn/T/ipykernel_6049/4045680862.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  y = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
      "/var/folders/fp/zkb1xvsx6s1gy5dwtqm90krc0000gn/T/ipykernel_6049/4045680862.py:47: RuntimeWarning: invalid value encountered in scalar add\n",
      "  y[u] += x[v]\n",
      "/var/folders/fp/zkb1xvsx6s1gy5dwtqm90krc0000gn/T/ipykernel_6049/4045680862.py:68: RuntimeWarning: invalid value encountered in divide\n",
      "  y = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
      "/var/folders/fp/zkb1xvsx6s1gy5dwtqm90krc0000gn/T/ipykernel_6049/4045680862.py:78: RuntimeWarning: invalid value encountered in divide\n",
      "  y = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of edges: 5278\n",
      "New number of edges: 5805\n",
      "Number of added edges: 527\n",
      "Original Graph - Aggregate Commute Time: 1.5311\n",
      "FOSR-modified Graph - Aggregate Commute Time: 1.2379\n",
      "Percentage change in Aggregate Commute Time: -19.15%\n"
     ]
    }
   ],
   "source": [
    "# Load the Cora dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# Convert to NetworkX graph\n",
    "G = to_networkx(data, to_undirected=True)\n",
    "\n",
    "# Get edge index from the graph\n",
    "edge_index = np.array(list(G.edges())).T\n",
    "\n",
    "# Apply FOSR to get new edge index\n",
    "new_edge_index, new_edge_type = apply_fosr_to_dataset(dataset)\n",
    "\n",
    "# Create a new graph with the rewired edges\n",
    "new_G = nx.Graph()\n",
    "new_G.add_nodes_from(range(data.num_nodes))\n",
    "new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "new_G.add_edges_from(new_edges)\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Original number of edges: {G.number_of_edges()}\")\n",
    "print(f\"New number of edges: {new_G.number_of_edges()}\")\n",
    "print(f\"Number of added edges: {new_G.number_of_edges() - G.number_of_edges()}\")\n",
    "\n",
    "# Calculate aggregate commute times for both graphs\n",
    "G_original = G  # Rename G to G_original for clarity\n",
    "G_fosr = new_G  # Rename new_G to G_fosr for consistency\n",
    "\n",
    "agg_commute_time_original = aggregate_commute_times(G_original)\n",
    "agg_commute_time_fosr = aggregate_commute_times(G_fosr)\n",
    "\n",
    "print(f\"Original Graph - Aggregate Commute Time: {agg_commute_time_original:.4f}\")\n",
    "print(f\"FOSR-modified Graph - Aggregate Commute Time: {agg_commute_time_fosr:.4f}\")\n",
    "\n",
    "# Calculate the percentage change in aggregate commute time\n",
    "percent_change = ((agg_commute_time_fosr - agg_commute_time_original) / agg_commute_time_original) * 100\n",
    "\n",
    "print(f\"Percentage change in Aggregate Commute Time: {percent_change:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_name, num_graphs=1000):\n",
    "    if dataset_name.lower() == 'zinc':\n",
    "        dataset = ZINC(root='/tmp/ZINC', subset=True)\n",
    "    elif dataset_name.lower() == 'qm9':\n",
    "        dataset = QM9(root='/tmp/QM9')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset name. Choose 'ZINC' or 'QM9'.\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(min(num_graphs, len(dataset))):\n",
    "        data = dataset[i]\n",
    "        \n",
    "        # Convert to NetworkX graph\n",
    "        G_original = to_networkx(data, to_undirected=True)\n",
    "        \n",
    "        # Get edge index from the graph\n",
    "        edge_index = np.array(list(G_original.edges())).T\n",
    "        \n",
    "        # Apply FOSR to get new edge index\n",
    "        new_edge_index, new_edge_type = apply_fosr(edge_index)\n",
    "        \n",
    "        # Create a new graph with the rewired edges\n",
    "        G_fosr = nx.Graph()\n",
    "        G_fosr.add_nodes_from(range(data.num_nodes))\n",
    "        new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "        G_fosr.add_edges_from(new_edges)\n",
    "        \n",
    "        # Calculate aggregate commute times for both graphs\n",
    "        agg_commute_time_original = aggregate_commute_times(G_original)\n",
    "        agg_commute_time_fosr = aggregate_commute_times(G_fosr)\n",
    "        \n",
    "        # Calculate the percentage change in aggregate commute time\n",
    "        percent_change = ((agg_commute_time_fosr - agg_commute_time_original) / agg_commute_time_original) * 100\n",
    "        \n",
    "        results.append({\n",
    "            'graph_index': i,\n",
    "            'original_edges': G_original.number_of_edges(),\n",
    "            'fosr_edges': G_fosr.number_of_edges(),\n",
    "            'added_edges': G_fosr.number_of_edges() - G_original.number_of_edges(),\n",
    "            'original_commute_time': agg_commute_time_original,\n",
    "            'fosr_commute_time': agg_commute_time_fosr,\n",
    "            'percent_change': percent_change\n",
    "        })\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i+1} graphs...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Process ZINC dataset\n",
    "print(\"Processing ZINC dataset...\")\n",
    "zinc_results = process_dataset('ZINC')\n",
    "\n",
    "# Process QM9 dataset\n",
    "print(\"\\nProcessing QM9 dataset...\")\n",
    "qm9_results = process_dataset('QM9')\n",
    "\n",
    "# Function to print summary statistics\n",
    "def print_summary(results, dataset_name):\n",
    "    avg_original_edges = np.mean([r['original_edges'] for r in results])\n",
    "    avg_fosr_edges = np.mean([r['fosr_edges'] for r in results])\n",
    "    avg_added_edges = np.mean([r['added_edges'] for r in results])\n",
    "    avg_original_commute_time = np.mean([r['original_commute_time'] for r in results])\n",
    "    avg_fosr_commute_time = np.mean([r['fosr_commute_time'] for r in results])\n",
    "    avg_percent_change = np.mean([r['percent_change'] for r in results])\n",
    "    \n",
    "    print(f\"\\nSummary for {dataset_name} dataset:\")\n",
    "    print(f\"Average original edges: {avg_original_edges:.2f}\")\n",
    "    print(f\"Average FOSR edges: {avg_fosr_edges:.2f}\")\n",
    "    print(f\"Average added edges: {avg_added_edges:.2f}\")\n",
    "    print(f\"Average original commute time: {avg_original_commute_time:.4f}\")\n",
    "    print(f\"Average FOSR commute time: {avg_fosr_commute_time:.4f}\")\n",
    "    print(f\"Average percentage change in commute time: {avg_percent_change:.2f}%\")\n",
    "\n",
    "# Print summaries\n",
    "print_summary(zinc_results, \"ZINC\")\n",
    "print_summary(qm9_results, \"QM9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx, to_scipy_sparse_matrix\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.linalg import pinv\n",
    "from math import inf\n",
    "from numba import jit, int64\n",
    "from torch_geometric.datasets import ZINC, QM9\n",
    "\n",
    "def choose_edge_to_add(x, edge_index, degrees):\n",
    "    # chooses edge (u, v) to add which minimizes y[u]*y[v]\n",
    "    n = x.size\n",
    "    m = edge_index.shape[1]\n",
    "    y = x / ((degrees + 1) ** 0.5)\n",
    "    products = np.outer(y, y)\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        products[u, v] = inf\n",
    "    for i in range(n):\n",
    "        products[i, i] = inf\n",
    "    smallest_product = np.argmin(products)\n",
    "    return (smallest_product % n, smallest_product // n)\n",
    "\n",
    "def compute_degrees(edge_index, num_nodes=None):\n",
    "    # returns array of degrees of all nodes\n",
    "    if num_nodes is None:\n",
    "        num_nodes = np.max(edge_index) + 1\n",
    "    degrees = np.zeros(num_nodes)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        degrees[edge_index[0, i]] += 1\n",
    "    return degrees\n",
    "\n",
    "def add_edge(edge_index, u, v):\n",
    "    new_edge = np.array([[u, v],[v, u]])\n",
    "    return np.concatenate((edge_index, new_edge), axis=1)\n",
    "\n",
    "def adj_matrix_multiply(edge_index, x):\n",
    "    # given an edge_index, computes Ax, where A is the corresponding adjacency matrix\n",
    "    n = x.size\n",
    "    y = np.zeros(n)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        y[u] += x[v]\n",
    "    return y\n",
    "\n",
    "def compute_spectral_gap(edge_index, x):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\ty = adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\tfor i in range(n):\n",
    "\t\tif x[i] > 1e-9:\n",
    "\t\t\treturn 1 - y[i]/x[i]\n",
    "\treturn 0.\n",
    "\n",
    "def _edge_rewire(edge_index, edge_type, x=None, num_iterations=50, initial_power_iters=50):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tif x is None:\n",
    "\t\tx = 2 * np.random.random(n) - 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\tfor i in range(initial_power_iters):\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\tfor I in range(num_iterations):\n",
    "\t\ti, j = choose_edge_to_add(x, edge_index, degrees=degrees)\n",
    "\t\tedge_index = add_edge(edge_index, i, j)\n",
    "\t\tdegrees[i] += 1\n",
    "\t\tdegrees[j] += 1\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\treturn edge_index, edge_type, x\n",
    "\n",
    "def edge_rewire(edge_index, x=None, edge_type=None, num_iterations=50, initial_power_iters=5):\n",
    "    m = edge_index.shape[1]\n",
    "    n = np.max(edge_index) + 1\n",
    "    if x is None:\n",
    "        x = 2 * np.random.random(n) - 1\n",
    "    if edge_type is None:\n",
    "        edge_type = np.zeros(m, dtype=np.int64)\n",
    "    return _edge_rewire(edge_index, edge_type=edge_type, x=x, num_iterations=num_iterations, initial_power_iters=initial_power_iters)\n",
    "\n",
    "\n",
    "# Apply the FOSR method\n",
    "def apply_fosr(edge_index, rewire_fraction=0.1, min_iterations=10, max_iterations=1000):\n",
    "    edge_type = np.zeros(edge_index.shape[1], dtype=np.int64)\n",
    "    n = np.max(edge_index) + 1\n",
    "    x = 2 * np.random.random(n) - 1\n",
    "    \n",
    "    # Calculate num_iterations based on the number of edges and rewire_fraction\n",
    "    num_edges = edge_index.shape[1]\n",
    "    num_iterations = int(num_edges * rewire_fraction)\n",
    "    \n",
    "    # Ensure num_iterations is within a reasonable range\n",
    "    num_iterations = max(min_iterations, min(num_iterations, max_iterations))\n",
    "    \n",
    "    print(f\"Number of iterations for FOSR: {num_iterations}\")\n",
    "    \n",
    "    new_edge_index, new_edge_type, _ = edge_rewire(\n",
    "        edge_index, \n",
    "        x=x, \n",
    "        edge_type=edge_type, \n",
    "        num_iterations=num_iterations, \n",
    "        initial_power_iters=5\n",
    "    )\n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "# Function to apply FOSR to any dataset\n",
    "def apply_fosr_to_dataset(dataset, rewire_fraction=0.1, min_iterations=10, max_iterations=1000):\n",
    "    data = dataset[0]\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    edge_index = np.array(list(G.edges())).T\n",
    "    \n",
    "    new_edge_index, new_edge_type = apply_fosr(edge_index, rewire_fraction, min_iterations, max_iterations)\n",
    "    \n",
    "    new_G = nx.Graph()\n",
    "    new_G.add_nodes_from(range(data.num_nodes))\n",
    "    new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "    new_G.add_edges_from(new_edges)\n",
    "    \n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "def compute_commute_time(graph):\n",
    "    \"\"\"\n",
    "    Compute the commute time for each pair of nodes in a graph.\n",
    "    :param graph: A NetworkX graph object.\n",
    "    :return: Commute time matrix (numpy array).\n",
    "    \"\"\"\n",
    "    # Convert graph to adjacency matrix (scipy sparse format)\n",
    "    adj_matrix = nx.adjacency_matrix(graph)\n",
    "    \n",
    "    # Compute degree matrix\n",
    "    degrees = np.array(adj_matrix.sum(axis=1)).flatten()\n",
    "    D = np.diag(degrees)\n",
    "    \n",
    "    # Compute Laplacian matrix L = D - A\n",
    "    L = D - adj_matrix.toarray()\n",
    "    \n",
    "    # Compute the pseudoinverse of the Laplacian\n",
    "    L_pseudo = pinv(L)\n",
    "    \n",
    "    # Compute commute time between all pairs of nodes\n",
    "    num_nodes = L.shape[0]\n",
    "    commute_time = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            commute_time[i, j] = L_pseudo[i, i] + L_pseudo[j, j] - 2 * L_pseudo[i, j]\n",
    "    \n",
    "    return commute_time\n",
    "\n",
    "\n",
    "def aggregate_commute_times(graph):\n",
    "    \"\"\"\n",
    "    Aggregate the commute times for a single graph.\n",
    "    :param graph: A NetworkX graph object.\n",
    "    :return: Average commute time across the graph.\n",
    "    \"\"\"\n",
    "    commute_times = compute_commute_time(graph)\n",
    "    \n",
    "    # Get upper triangular part of the commute time matrix (since it's symmetric)\n",
    "    upper_triangle_indices = np.triu_indices_from(commute_times, k=1)\n",
    "    commute_times_upper = commute_times[upper_triangle_indices]\n",
    "    \n",
    "    # Return average commute time\n",
    "    return np.mean(commute_times_upper)\n",
    "\n",
    "# Load the Cora dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# Convert to NetworkX graph\n",
    "G = to_networkx(data, to_undirected=True)\n",
    "\n",
    "# Get edge index from the graph\n",
    "edge_index = np.array(list(G.edges())).T\n",
    "\n",
    "# Apply FOSR to get new edge index\n",
    "new_edge_index, new_edge_type = apply_fosr_to_dataset(dataset)\n",
    "\n",
    "# Create a new graph with the rewired edges\n",
    "new_G = nx.Graph()\n",
    "new_G.add_nodes_from(range(data.num_nodes))\n",
    "new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "new_G.add_edges_from(new_edges)\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Original number of edges: {G.number_of_edges()}\")\n",
    "print(f\"New number of edges: {new_G.number_of_edges()}\")\n",
    "print(f\"Number of added edges: {new_G.number_of_edges() - G.number_of_edges()}\")\n",
    "\n",
    "# Calculate aggregate commute times for both graphs\n",
    "G_original = G  # Rename G to G_original for clarity\n",
    "G_fosr = new_G  # Rename new_G to G_fosr for consistency\n",
    "\n",
    "agg_commute_time_original = aggregate_commute_times(G_original)\n",
    "agg_commute_time_fosr = aggregate_commute_times(G_fosr)\n",
    "\n",
    "print(f\"Original Graph - Aggregate Commute Time: {agg_commute_time_original:.4f}\")\n",
    "print(f\"FOSR-modified Graph - Aggregate Commute Time: {agg_commute_time_fosr:.4f}\")\n",
    "\n",
    "# Calculate the percentage change in aggregate commute time\n",
    "percent_change = ((agg_commute_time_fosr - agg_commute_time_original) / agg_commute_time_original) * 100\n",
    "\n",
    "print(f\"Percentage change in Aggregate Commute Time: {percent_change:.2f}%\")\n",
    "\n",
    "def process_dataset(dataset_name, num_graphs=1000):\n",
    "    if dataset_name.lower() == 'zinc':\n",
    "        dataset = ZINC(root='/tmp/ZINC', subset=False)\n",
    "    elif dataset_name.lower() == 'qm9':\n",
    "        dataset = QM9(root='/tmp/QM9')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset name. Choose 'ZINC' or 'QM9'.\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(min(num_graphs, len(dataset))):\n",
    "        data = dataset[i]\n",
    "        \n",
    "        # Convert to NetworkX graph\n",
    "        G_original = to_networkx(data, to_undirected=True)\n",
    "        \n",
    "        # Get edge index from the graph\n",
    "        edge_index = np.array(list(G_original.edges())).T\n",
    "        \n",
    "        # Apply FOSR to get new edge index\n",
    "        new_edge_index, new_edge_type = apply_fosr(edge_index)\n",
    "        \n",
    "        # Create a new graph with the rewired edges\n",
    "        G_fosr = nx.Graph()\n",
    "        G_fosr.add_nodes_from(range(data.num_nodes))\n",
    "        new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "        G_fosr.add_edges_from(new_edges)\n",
    "        \n",
    "        # Calculate aggregate commute times for both graphs\n",
    "        agg_commute_time_original = aggregate_commute_times(G_original)\n",
    "        agg_commute_time_fosr = aggregate_commute_times(G_fosr)\n",
    "        \n",
    "        # Calculate the percentage change in aggregate commute time\n",
    "        percent_change = ((agg_commute_time_fosr - agg_commute_time_original) / agg_commute_time_original) * 100\n",
    "        \n",
    "        results.append({\n",
    "            'graph_index': i,\n",
    "            'original_edges': G_original.number_of_edges(),\n",
    "            'fosr_edges': G_fosr.number_of_edges(),\n",
    "            'added_edges': G_fosr.number_of_edges() - G_original.number_of_edges(),\n",
    "            'original_commute_time': agg_commute_time_original,\n",
    "            'fosr_commute_time': agg_commute_time_fosr,\n",
    "            'percent_change': percent_change\n",
    "        })\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i+1} graphs...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Process ZINC dataset\n",
    "print(\"Processing ZINC dataset...\")\n",
    "zinc_results = process_dataset('ZINC')\n",
    "\n",
    "# Process QM9 dataset\n",
    "print(\"\\nProcessing QM9 dataset...\")\n",
    "qm9_results = process_dataset('QM9')\n",
    "\n",
    "# Function to print summary statistics\n",
    "def print_summary(results, dataset_name):\n",
    "    avg_original_edges = np.mean([r['original_edges'] for r in results])\n",
    "    avg_fosr_edges = np.mean([r['fosr_edges'] for r in results])\n",
    "    avg_added_edges = np.mean([r['added_edges'] for r in results])\n",
    "    avg_original_commute_time = np.mean([r['original_commute_time'] for r in results])\n",
    "    avg_fosr_commute_time = np.mean([r['fosr_commute_time'] for r in results])\n",
    "    avg_percent_change = np.mean([r['percent_change'] for r in results])\n",
    "    \n",
    "    print(f\"\\nSummary for {dataset_name} dataset:\")\n",
    "    print(f\"Average original edges: {avg_original_edges:.2f}\")\n",
    "    print(f\"Average FOSR edges: {avg_fosr_edges:.2f}\")\n",
    "    print(f\"Average added edges: {avg_added_edges:.2f}\")\n",
    "    print(f\"Average original commute time: {avg_original_commute_time:.4f}\")\n",
    "    print(f\"Average FOSR commute time: {avg_fosr_commute_time:.4f}\")\n",
    "    print(f\"Average percentage change in commute time: {avg_percent_change:.2f}%\")\n",
    "\n",
    "# Print summaries\n",
    "print_summary(zinc_results, \"ZINC\")\n",
    "print_summary(qm9_results, \"QM9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second try\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx, to_scipy_sparse_matrix\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.linalg import pinv\n",
    "from math import inf\n",
    "from numba import jit, int64\n",
    "from torch_geometric.datasets import ZINC, QM9\n",
    "\n",
    "def choose_edge_to_add(x, edge_index, degrees):\n",
    "    # chooses edge (u, v) to add which minimizes y[u]*y[v]\n",
    "    n = x.size\n",
    "    m = edge_index.shape[1]\n",
    "    y = x / ((degrees + 1) ** 0.5)\n",
    "    products = np.outer(y, y)\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        products[u, v] = inf\n",
    "    for i in range(n):\n",
    "        products[i, i] = inf\n",
    "    smallest_product = np.argmin(products)\n",
    "    return (smallest_product % n, smallest_product // n)\n",
    "\n",
    "def compute_degrees(edge_index, num_nodes=None):\n",
    "    # returns array of degrees of all nodes\n",
    "    if num_nodes is None:\n",
    "        num_nodes = np.max(edge_index) + 1\n",
    "    degrees = np.zeros(num_nodes)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        degrees[edge_index[0, i]] += 1\n",
    "    return degrees\n",
    "\n",
    "def add_edge(edge_index, u, v):\n",
    "    new_edge = np.array([[u, v],[v, u]])\n",
    "    return np.concatenate((edge_index, new_edge), axis=1)\n",
    "\n",
    "def adj_matrix_multiply(edge_index, x):\n",
    "    # given an edge_index, computes Ax, where A is the corresponding adjacency matrix\n",
    "    n = x.size\n",
    "    y = np.zeros(n)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        y[u] += x[v]\n",
    "    return y\n",
    "\n",
    "def compute_spectral_gap(edge_index, x):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\ty = adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\tfor i in range(n):\n",
    "\t\tif x[i] > 1e-9:\n",
    "\t\t\treturn 1 - y[i]/x[i]\n",
    "\treturn 0.\n",
    "\n",
    "def _edge_rewire(edge_index, edge_type, x=None, num_iterations=50, initial_power_iters=50):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tif x is None:\n",
    "\t\tx = 2 * np.random.random(n) - 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\tfor i in range(initial_power_iters):\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\tfor I in range(num_iterations):\n",
    "\t\ti, j = choose_edge_to_add(x, edge_index, degrees=degrees)\n",
    "\t\tedge_index = add_edge(edge_index, i, j)\n",
    "\t\tdegrees[i] += 1\n",
    "\t\tdegrees[j] += 1\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\treturn edge_index, edge_type, x\n",
    "\n",
    "def edge_rewire(edge_index, x=None, edge_type=None, num_iterations=50, initial_power_iters=5):\n",
    "    m = edge_index.shape[1]\n",
    "    n = np.max(edge_index) + 1\n",
    "    if x is None:\n",
    "        x = 2 * np.random.random(n) - 1\n",
    "    if edge_type is None:\n",
    "        edge_type = np.zeros(m, dtype=np.int64)\n",
    "    return _edge_rewire(edge_index, edge_type=edge_type, x=x, num_iterations=num_iterations, initial_power_iters=initial_power_iters)\n",
    "\n",
    "\n",
    "# Apply the FOSR method\n",
    "def apply_fosr(edge_index, rewire_fraction=0.1, min_iterations=10, max_iterations=1000):\n",
    "    edge_type = np.zeros(edge_index.shape[1], dtype=np.int64)\n",
    "    n = np.max(edge_index) + 1\n",
    "    x = 2 * np.random.random(n) - 1\n",
    "    \n",
    "    # Calculate num_iterations based on the number of edges and rewire_fraction\n",
    "    num_edges = edge_index.shape[1]\n",
    "    num_iterations = int(num_edges * rewire_fraction)\n",
    "    \n",
    "    # Ensure num_iterations is within a reasonable range\n",
    "    num_iterations = max(min_iterations, min(num_iterations, max_iterations))\n",
    "    \n",
    "    print(f\"Number of iterations for FOSR: {num_iterations}\")\n",
    "    \n",
    "    new_edge_index, new_edge_type, _ = edge_rewire(\n",
    "        edge_index, \n",
    "        x=x, \n",
    "        edge_type=edge_type, \n",
    "        num_iterations=num_iterations, \n",
    "        initial_power_iters=5\n",
    "    )\n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "# Function to apply FOSR to any dataset\n",
    "def apply_fosr_to_dataset(dataset, rewire_fraction=0.1, min_iterations=10, max_iterations=1000):\n",
    "    data = dataset[0]\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    edge_index = np.array(list(G.edges())).T\n",
    "    \n",
    "    new_edge_index, new_edge_type = apply_fosr(edge_index, rewire_fraction, min_iterations, max_iterations)\n",
    "    \n",
    "    new_G = nx.Graph()\n",
    "    new_G.add_nodes_from(range(data.num_nodes))\n",
    "    new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "    new_G.add_edges_from(new_edges)\n",
    "    \n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "def compute_commute_time(graph):\n",
    "    \"\"\"\n",
    "    Compute the commute time for each pair of nodes in a graph.\n",
    "    :param graph: A NetworkX graph object.\n",
    "    :return: Commute time matrix (numpy array).\n",
    "    \"\"\"\n",
    "    # Convert graph to adjacency matrix (scipy sparse format)\n",
    "    adj_matrix = nx.adjacency_matrix(graph)\n",
    "    \n",
    "    # Compute degree matrix\n",
    "    degrees = np.array(adj_matrix.sum(axis=1)).flatten()\n",
    "    D = np.diag(degrees)\n",
    "    \n",
    "    # Compute Laplacian matrix L = D - A\n",
    "    L = D - adj_matrix.toarray()\n",
    "    \n",
    "    # Compute the pseudoinverse of the Laplacian\n",
    "    L_pseudo = pinv(L)\n",
    "    \n",
    "    # Compute commute time between all pairs of nodes\n",
    "    num_nodes = L.shape[0]\n",
    "    commute_time = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            commute_time[i, j] = L_pseudo[i, i] + L_pseudo[j, j] - 2 * L_pseudo[i, j]\n",
    "    \n",
    "    return commute_time\n",
    "\n",
    "\n",
    "def aggregate_commute_times(graph):\n",
    "    \"\"\"\n",
    "    Aggregate the commute times for a single graph.\n",
    "    :param graph: A NetworkX graph object.\n",
    "    :return: Average commute time across the graph.\n",
    "    \"\"\"\n",
    "    commute_times = compute_commute_time(graph)\n",
    "    \n",
    "    # Get upper triangular part of the commute time matrix (since it's symmetric)\n",
    "    upper_triangle_indices = np.triu_indices_from(commute_times, k=1)\n",
    "    commute_times_upper = commute_times[upper_triangle_indices]\n",
    "    \n",
    "    # Return average commute time\n",
    "    return np.mean(commute_times_upper)\n",
    "\n",
    "def apply_fosr(edge_index, rewire_fraction=0.1, min_iterations=10, max_iterations=1000):\n",
    "    edge_type = np.zeros(edge_index.shape[1], dtype=np.int64)\n",
    "    n = np.max(edge_index) + 1\n",
    "    x = 2 * np.random.random(n) - 1\n",
    "    \n",
    "    num_edges = edge_index.shape[1]\n",
    "    num_iterations = int(num_edges * rewire_fraction)\n",
    "    num_iterations = max(min_iterations, min(num_iterations, max_iterations))\n",
    "    \n",
    "    new_edge_index, new_edge_type, _ = edge_rewire(\n",
    "        edge_index, \n",
    "        x=x, \n",
    "        edge_type=edge_type, \n",
    "        num_iterations=num_iterations, \n",
    "        initial_power_iters=5\n",
    "    )\n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "def process_dataset(dataset_name):\n",
    "    if dataset_name.lower() == 'zinc':\n",
    "        dataset = ZINC(root='/tmp/ZINC', subset=False)  # Using the full dataset\n",
    "    elif dataset_name.lower() == 'qm9':\n",
    "        dataset = QM9(root='/tmp/QM9')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset name. Choose 'ZINC' or 'QM9'.\")\n",
    "    \n",
    "    total_original_edges = 0\n",
    "    total_fosr_edges = 0\n",
    "    total_graphs = len(dataset)\n",
    "    \n",
    "    for i, data in enumerate(dataset):\n",
    "        # Convert to NetworkX graph\n",
    "        G_original = to_networkx(data, to_undirected=True)\n",
    "        \n",
    "        # Get edge index from the graph\n",
    "        edge_index = np.array(list(G_original.edges())).T\n",
    "        \n",
    "        # Apply FOSR to get new edge index\n",
    "        new_edge_index, _ = apply_fosr(edge_index)\n",
    "        \n",
    "        # Create a new graph with the rewired edges\n",
    "        G_fosr = nx.Graph()\n",
    "        G_fosr.add_nodes_from(range(data.num_nodes))\n",
    "        new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "        G_fosr.add_edges_from(new_edges)\n",
    "        \n",
    "        total_original_edges += G_original.number_of_edges()\n",
    "        total_fosr_edges += G_fosr.number_of_edges()\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Processed {i+1}/{total_graphs} graphs...\")\n",
    "    \n",
    "    return total_original_edges, total_fosr_edges, total_graphs\n",
    "\n",
    "# Function to print summary statistics\n",
    "def print_summary(original_edges, fosr_edges, total_graphs, dataset_name):\n",
    "    print(f\"\\nSummary for {dataset_name} dataset:\")\n",
    "    print(f\"Total graphs processed: {total_graphs}\")\n",
    "    print(f\"Number of original edges: {original_edges}\")\n",
    "    print(f\"Number of edges in FOSR dataset: {fosr_edges}\")\n",
    "    print(f\"Difference in edges: {fosr_edges - original_edges}\")\n",
    "\n",
    "# Process ZINC dataset\n",
    "print(\"Processing ZINC dataset...\")\n",
    "zinc_original, zinc_fosr, zinc_graphs = process_dataset('ZINC')\n",
    "\n",
    "# Process QM9 dataset\n",
    "print(\"\\nProcessing QM9 dataset...\")\n",
    "qm9_original, qm9_fosr, qm9_graphs = process_dataset('QM9')\n",
    "\n",
    "# Print summaries\n",
    "print_summary(zinc_original, zinc_fosr, zinc_graphs, \"ZINC\")\n",
    "print_summary(qm9_original, qm9_fosr, qm9_graphs, \"QM9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing ZINC dataset...\n",
    "/content/spectral.py:69: RuntimeWarning: divide by zero encountered in divide\n",
    "  y = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "/content/spectral.py:69: RuntimeWarning: invalid value encountered in divide\n",
    "  y = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "/content/spectral.py:79: RuntimeWarning: invalid value encountered in divide\n",
    "  y = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "/content/spectral.py:48: RuntimeWarning: invalid value encountered in scalar add\n",
    "  y[u] += x[v]\n",
    "Processed 10000/220011 graphs...\n",
    "Processed 20000/220011 graphs...\n",
    "Processed 30000/220011 graphs...\n",
    "Processed 40000/220011 graphs...\n",
    "Processed 50000/220011 graphs...\n",
    "Processed 60000/220011 graphs...\n",
    "Processed 70000/220011 graphs...\n",
    "Processed 80000/220011 graphs...\n",
    "Processed 90000/220011 graphs...\n",
    "Processed 100000/220011 graphs...\n",
    "Processed 110000/220011 graphs...\n",
    "Processed 120000/220011 graphs...\n",
    "Processed 130000/220011 graphs...\n",
    "Processed 140000/220011 graphs...\n",
    "Processed 150000/220011 graphs...\n",
    "Processed 160000/220011 graphs...\n",
    "Processed 170000/220011 graphs...\n",
    "Processed 180000/220011 graphs...\n",
    "Processed 190000/220011 graphs...\n",
    "Processed 200000/220011 graphs...\n",
    "Processed 210000/220011 graphs...\n",
    "Processed 220000/220011 graphs...\n",
    "\n",
    "Processing QM9 dataset...\n",
    "Processed 10000/130831 graphs...\n",
    "Processed 20000/130831 graphs...\n",
    "Processed 30000/130831 graphs...\n",
    "Processed 40000/130831 graphs...\n",
    "Processed 50000/130831 graphs...\n",
    "Processed 60000/130831 graphs...\n",
    "Processed 70000/130831 graphs...\n",
    "Processed 80000/130831 graphs...\n",
    "Processed 90000/130831 graphs...\n",
    "Processed 100000/130831 graphs...\n",
    "Processed 110000/130831 graphs...\n",
    "Processed 120000/130831 graphs...\n",
    "Processed 130000/130831 graphs...\n",
    "\n",
    "Summary for ZINC dataset:\n",
    "Total graphs processed: 220011\n",
    "Number of original edges: 5479717\n",
    "Number of edges in FOSR dataset: 7678922\n",
    "Difference in edges: 2199205\n",
    "Average original commute time: 4.2192\n",
    "Average FOSR commute time: 2.2814\n",
    "Percentage change in commute time: -45.93%\n",
    "\n",
    "Summary for QM9 dataset:\n",
    "Total graphs processed: 130831\n",
    "Number of original edges: 2441758\n",
    "Number of edges in FOSR dataset: 3742733\n",
    "Difference in edges: 1300975\n",
    "Average original commute time: 2.7984\n",
    "Average FOSR commute time: 1.2852\n",
    "Percentage change in commute time: -54.07%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#third try\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx, to_scipy_sparse_matrix\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.linalg import pinv\n",
    "from math import inf\n",
    "from numba import jit, int64\n",
    "from torch_geometric.datasets import ZINC, QM9\n",
    "\n",
    "def choose_edge_to_add(x, edge_index, degrees):\n",
    "    # chooses edge (u, v) to add which minimizes y[u]*y[v]\n",
    "    n = x.size\n",
    "    m = edge_index.shape[1]\n",
    "    y = x / ((degrees + 1) ** 0.5)\n",
    "    products = np.outer(y, y)\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        products[u, v] = inf\n",
    "    for i in range(n):\n",
    "        products[i, i] = inf\n",
    "    smallest_product = np.argmin(products)\n",
    "    return (smallest_product % n, smallest_product // n)\n",
    "\n",
    "def compute_degrees(edge_index, num_nodes=None):\n",
    "    # returns array of degrees of all nodes\n",
    "    if num_nodes is None:\n",
    "        num_nodes = np.max(edge_index) + 1\n",
    "    degrees = np.zeros(num_nodes)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        degrees[edge_index[0, i]] += 1\n",
    "    return degrees\n",
    "\n",
    "def add_edge(edge_index, u, v):\n",
    "    new_edge = np.array([[u, v],[v, u]])\n",
    "    return np.concatenate((edge_index, new_edge), axis=1)\n",
    "\n",
    "def adj_matrix_multiply(edge_index, x):\n",
    "    # given an edge_index, computes Ax, where A is the corresponding adjacency matrix\n",
    "    n = x.size\n",
    "    y = np.zeros(n)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        y[u] += x[v]\n",
    "    return y\n",
    "\n",
    "def compute_spectral_gap(edge_index, x):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\ty = adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\tfor i in range(n):\n",
    "\t\tif x[i] > 1e-9:\n",
    "\t\t\treturn 1 - y[i]/x[i]\n",
    "\treturn 0.\n",
    "\n",
    "def _edge_rewire(edge_index, edge_type, x=None, num_iterations=50, initial_power_iters=50):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tif x is None:\n",
    "\t\tx = 2 * np.random.random(n) - 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\tfor i in range(initial_power_iters):\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\tfor I in range(num_iterations):\n",
    "\t\ti, j = choose_edge_to_add(x, edge_index, degrees=degrees)\n",
    "\t\tedge_index = add_edge(edge_index, i, j)\n",
    "\t\tdegrees[i] += 1\n",
    "\t\tdegrees[j] += 1\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\treturn edge_index, edge_type, x\n",
    "\n",
    "def edge_rewire(edge_index, x=None, edge_type=None, num_iterations=50, initial_power_iters=5):\n",
    "    m = edge_index.shape[1]\n",
    "    n = np.max(edge_index) + 1\n",
    "    if x is None:\n",
    "        x = 2 * np.random.random(n) - 1\n",
    "    if edge_type is None:\n",
    "        edge_type = np.zeros(m, dtype=np.int64)\n",
    "    return _edge_rewire(edge_index, edge_type=edge_type, x=x, num_iterations=num_iterations, initial_power_iters=initial_power_iters)\n",
    "\n",
    "\n",
    "# Apply the FOSR method\n",
    "def apply_fosr(edge_index, rewire_fraction=0.1, min_iterations=10, max_iterations=1000):\n",
    "    edge_type = np.zeros(edge_index.shape[1], dtype=np.int64)\n",
    "    n = np.max(edge_index) + 1\n",
    "    x = 2 * np.random.random(n) - 1\n",
    "    \n",
    "    # Calculate num_iterations based on the number of edges and rewire_fraction\n",
    "    num_edges = edge_index.shape[1]\n",
    "    num_iterations = int(num_edges * rewire_fraction)\n",
    "    \n",
    "    # Ensure num_iterations is within a reasonable range\n",
    "    num_iterations = max(min_iterations, min(num_iterations, max_iterations))\n",
    "    \n",
    "    print(f\"Number of iterations for FOSR: {num_iterations}\")\n",
    "    \n",
    "    new_edge_index, new_edge_type, _ = edge_rewire(\n",
    "        edge_index, \n",
    "        x=x, \n",
    "        edge_type=edge_type, \n",
    "        num_iterations=num_iterations, \n",
    "        initial_power_iters=5\n",
    "    )\n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "# Function to apply FOSR to any dataset\n",
    "def apply_fosr_to_dataset(dataset, rewire_fraction=0.1, min_iterations=10, max_iterations=1000):\n",
    "    data = dataset[0]\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    edge_index = np.array(list(G.edges())).T\n",
    "    \n",
    "    new_edge_index, new_edge_type = apply_fosr(edge_index, rewire_fraction, min_iterations, max_iterations)\n",
    "    \n",
    "    new_G = nx.Graph()\n",
    "    new_G.add_nodes_from(range(data.num_nodes))\n",
    "    new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "    new_G.add_edges_from(new_edges)\n",
    "    \n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "def compute_commute_time(graph):\n",
    "    \"\"\"\n",
    "    Compute the commute time for each pair of nodes in a graph.\n",
    "    :param graph: A NetworkX graph object.\n",
    "    :return: Commute time matrix (numpy array).\n",
    "    \"\"\"\n",
    "    # Convert graph to adjacency matrix (scipy sparse format)\n",
    "    adj_matrix = nx.adjacency_matrix(graph)\n",
    "    \n",
    "    # Compute degree matrix\n",
    "    degrees = np.array(adj_matrix.sum(axis=1)).flatten()\n",
    "    D = np.diag(degrees)\n",
    "    \n",
    "    # Compute Laplacian matrix L = D - A\n",
    "    L = D - adj_matrix.toarray()\n",
    "    \n",
    "    # Compute the pseudoinverse of the Laplacian\n",
    "    L_pseudo = pinv(L)\n",
    "    \n",
    "    # Compute commute time between all pairs of nodes\n",
    "    num_nodes = L.shape[0]\n",
    "    commute_time = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            commute_time[i, j] = L_pseudo[i, i] + L_pseudo[j, j] - 2 * L_pseudo[i, j]\n",
    "    \n",
    "    return commute_time\n",
    "\n",
    "\n",
    "def aggregate_commute_times(graph):\n",
    "    \"\"\"\n",
    "    Aggregate the commute times for a single graph.\n",
    "    :param graph: A NetworkX graph object.\n",
    "    :return: Average commute time across the graph.\n",
    "    \"\"\"\n",
    "    commute_times = compute_commute_time(graph)\n",
    "    \n",
    "    # Get upper triangular part of the commute time matrix (since it's symmetric)\n",
    "    upper_triangle_indices = np.triu_indices_from(commute_times, k=1)\n",
    "    commute_times_upper = commute_times[upper_triangle_indices]\n",
    "    \n",
    "    # Return average commute time\n",
    "    return np.mean(commute_times_upper)\n",
    "\n",
    "def apply_fosr(edge_index, max_new_edges):\n",
    "    edge_type = np.zeros(edge_index.shape[1], dtype=np.int64)\n",
    "    n = np.max(edge_index) + 1\n",
    "    x = 2 * np.random.random(n) - 1\n",
    "    \n",
    "    new_edge_index, new_edge_type, _ = edge_rewire(\n",
    "        edge_index, \n",
    "        x=x, \n",
    "        edge_type=edge_type, \n",
    "        num_iterations=max_new_edges, \n",
    "        initial_power_iters=5\n",
    "    )\n",
    "    \n",
    "    return new_edge_index, new_edge_type\n",
    "\n",
    "def process_dataset(dataset_name):\n",
    "    if dataset_name.lower() == 'zinc':\n",
    "        dataset = ZINC(root='/tmp/ZINC', subset=False)  # Using the full dataset\n",
    "    elif dataset_name.lower() == 'qm9':\n",
    "        dataset = QM9(root='/tmp/QM9')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset name. Choose 'ZINC' or 'QM9'.\")\n",
    "    \n",
    "    total_original_edges = 0\n",
    "    total_fosr_edges = 0\n",
    "    total_original_commute_time = 0\n",
    "    total_fosr_commute_time = 0\n",
    "    total_graphs = len(dataset)\n",
    "    \n",
    "    for i, data in enumerate(dataset):\n",
    "        # Convert to NetworkX graph\n",
    "        G_original = to_networkx(data, to_undirected=True)\n",
    "        \n",
    "        # Get edge index from the graph\n",
    "        edge_index = np.array(list(G_original.edges())).T\n",
    "        \n",
    "        # Calculate max new edges (10% of original edges)\n",
    "        max_new_edges = int(0.1 * G_original.number_of_edges())\n",
    "        \n",
    "        # Apply FOSR to get new edge index\n",
    "        new_edge_index, _ = apply_fosr(edge_index, max_new_edges)\n",
    "        \n",
    "        # Create a new graph with the rewired edges\n",
    "        G_fosr = nx.Graph()\n",
    "        G_fosr.add_nodes_from(range(data.num_nodes))\n",
    "        new_edges = list(zip(new_edge_index[0], new_edge_index[1]))\n",
    "        G_fosr.add_edges_from(new_edges)\n",
    "        \n",
    "        # Calculate commute times\n",
    "        original_commute_time = aggregate_commute_times(G_original)\n",
    "        fosr_commute_time = aggregate_commute_times(G_fosr)\n",
    "        \n",
    "        total_original_edges += G_original.number_of_edges()\n",
    "        total_fosr_edges += G_fosr.number_of_edges()\n",
    "        total_original_commute_time += original_commute_time\n",
    "        total_fosr_commute_time += fosr_commute_time\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Processed {i+1}/{total_graphs} graphs...\")\n",
    "    \n",
    "    return total_original_edges, total_fosr_edges, total_original_commute_time, total_fosr_commute_time, total_graphs\n",
    "\n",
    "# Function to print summary statistics\n",
    "def print_summary(original_edges, fosr_edges, original_commute_time, fosr_commute_time, total_graphs, dataset_name):\n",
    "    print(f\"\\nSummary for {dataset_name} dataset:\")\n",
    "    print(f\"Total graphs processed: {total_graphs}\")\n",
    "    print(f\"Number of original edges: {original_edges}\")\n",
    "    print(f\"Number of edges in FOSR dataset: {fosr_edges}\")\n",
    "    print(f\"Difference in edges: {fosr_edges - original_edges}\")\n",
    "    print(f\"Percentage of edges added: {((fosr_edges - original_edges) / original_edges) * 100:.2f}%\")\n",
    "    print(f\"Average original commute time: {original_commute_time / total_graphs:.4f}\")\n",
    "    print(f\"Average FOSR commute time: {fosr_commute_time / total_graphs:.4f}\")\n",
    "    print(f\"Percentage change in commute time: {((fosr_commute_time - original_commute_time) / original_commute_time) * 100:.2f}%\")\n",
    "\n",
    "# Process ZINC dataset\n",
    "print(\"Processing ZINC dataset...\")\n",
    "zinc_original, zinc_fosr, zinc_original_ct, zinc_fosr_ct, zinc_graphs = process_dataset('ZINC')\n",
    "\n",
    "# Process QM9 dataset\n",
    "print(\"\\nProcessing QM9 dataset...\")\n",
    "qm9_original, qm9_fosr, qm9_original_ct, qm9_fosr_ct, qm9_graphs = process_dataset('QM9')\n",
    "\n",
    "# Print summaries\n",
    "print_summary(zinc_original, zinc_fosr, zinc_original_ct, zinc_fosr_ct, zinc_graphs, \"ZINC\")\n",
    "print_summary(qm9_original, qm9_fosr, qm9_original_ct, qm9_fosr_ct, qm9_graphs, \"QM9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing ZINC dataset...\n",
    "/content/spectral.py:71: RuntimeWarning: divide by zero encountered in divide\n",
    "  y = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "/content/spectral.py:50: RuntimeWarning: invalid value encountered in scalar add\n",
    "  y[u] += x[v]\n",
    "/content/spectral.py:71: RuntimeWarning: invalid value encountered in divide\n",
    "  y = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "/content/spectral.py:81: RuntimeWarning: invalid value encountered in divide\n",
    "  y = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "Processed 10000/220011 graphs...\n",
    "Processed 20000/220011 graphs...\n",
    "Processed 30000/220011 graphs...\n",
    "Processed 40000/220011 graphs...\n",
    "Processed 50000/220011 graphs...\n",
    "Processed 60000/220011 graphs...\n",
    "Processed 70000/220011 graphs...\n",
    "Processed 80000/220011 graphs...\n",
    "Processed 90000/220011 graphs...\n",
    "Processed 100000/220011 graphs...\n",
    "Processed 110000/220011 graphs...\n",
    "Processed 120000/220011 graphs...\n",
    "Processed 130000/220011 graphs...\n",
    "Processed 140000/220011 graphs...\n",
    "Processed 150000/220011 graphs...\n",
    "Processed 160000/220011 graphs...\n",
    "Processed 170000/220011 graphs...\n",
    "Processed 180000/220011 graphs...\n",
    "Processed 190000/220011 graphs...\n",
    "Processed 200000/220011 graphs...\n",
    "Processed 210000/220011 graphs...\n",
    "Processed 220000/220011 graphs...\n",
    "\n",
    "Processing QM9 dataset...\n",
    "Processed 10000/130831 graphs...\n",
    "Processed 20000/130831 graphs...\n",
    "Processed 30000/130831 graphs...\n",
    "Processed 40000/130831 graphs...\n",
    "Processed 50000/130831 graphs...\n",
    "Processed 60000/130831 graphs...\n",
    "Processed 70000/130831 graphs...\n",
    "Processed 80000/130831 graphs...\n",
    "Processed 90000/130831 graphs...\n",
    "Processed 100000/130831 graphs...\n",
    "Processed 110000/130831 graphs...\n",
    "Processed 120000/130831 graphs...\n",
    "Processed 130000/130831 graphs...\n",
    "\n",
    "Summary for ZINC dataset:\n",
    "Total graphs processed: 220011\n",
    "Number of original edges: 5479717\n",
    "Number of edges in FOSR dataset: 5926297\n",
    "Difference in edges: 446580\n",
    "Percentage of edges added: 8.15%\n",
    "Average original commute time: 4.2192\n",
    "Average FOSR commute time: 3.9500\n",
    "Percentage change in commute time: -6.38%\n",
    "\n",
    "Summary for QM9 dataset:\n",
    "Total graphs processed: 130831\n",
    "Number of original edges: 2441758\n",
    "Number of edges in FOSR dataset: 2626425\n",
    "Difference in edges: 184667\n",
    "Percentage of edges added: 7.56%\n",
    "Average original commute time: 2.7984\n",
    "Average FOSR commute time: 2.4197\n",
    "Percentage change in commute time: -13.53%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_and_evaluate(model, data, optimizer, num_epochs=200):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    return acc\n",
    "\n",
    "def compare_performance(original_graph, fosr_graph):\n",
    "    # Assume node features and labels are available in the graphs\n",
    "    original_data = Data(x=original_graph.x, edge_index=original_graph.edge_index, y=original_graph.y)\n",
    "    fosr_data = Data(x=fosr_graph.x, edge_index=fosr_graph.edge_index, y=fosr_graph.y)\n",
    "    \n",
    "    num_features = original_data.num_node_features\n",
    "    num_classes = original_data.y.max().item() + 1\n",
    "\n",
    "    original_model = GCN(num_features, num_classes)\n",
    "    fosr_model = GCN(num_features, num_classes)\n",
    "\n",
    "    original_optimizer = torch.optim.Adam(original_model.parameters(), lr=0.01)\n",
    "    fosr_optimizer = torch.optim.Adam(fosr_model.parameters(), lr=0.01)\n",
    "\n",
    "    original_acc = train_and_evaluate(original_model, original_data, original_optimizer)\n",
    "    fosr_acc = train_and_evaluate(fosr_model, fosr_data, fosr_optimizer)\n",
    "\n",
    "    print(f\"Original Graph Accuracy: {original_acc:.4f}\")\n",
    "    print(f\"FOSR-modified Graph Accuracy: {fosr_acc:.4f}\")\n",
    "\n",
    "# You would call this function for each graph in your dataset\n",
    "# compare_performance(original_graph, fosr_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
