{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GINConv, BatchNorm, global_add_pool\n",
    "\n",
    "\n",
    "with open('/Users/nasibhuseynzade/Downloads/zinc_dataset.pkl','rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model, dataset, rewired_dataset, num_epochs=4, batch_size=32, learning_rate=0.0005):\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    rewired_train_size = int(0.8 * len(rewired_dataset))\n",
    "    rewired_test_size = len(rewired_dataset) - rewired_train_size\n",
    "    rewired_train_dataset, rewired_test_dataset = torch.utils.data.random_split(rewired_dataset, [rewired_train_size, rewired_test_size])\n",
    "\n",
    "    train_loader = GeoDataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = GeoDataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    rewired_train_loader = GeoDataLoader(rewired_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    rewired_test_loader = GeoDataLoader(rewired_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    train_losses = []\n",
    "    original_r2_scores = []\n",
    "    rewired_r2_scores = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    " \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            batch.x = batch.x.float()\n",
    "            batch.y = batch.y.float().view(-1, 1)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch)  \n",
    "            \n",
    "            loss = F.mse_loss(out, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        test_preds, test_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                batch.x = batch.x.float()\n",
    "                batch.y = batch.y.float().view(-1, 1)\n",
    "            \n",
    "                out = model(batch)\n",
    "                test_targets.append(batch.y.cpu().numpy())\n",
    "                test_preds.append(out.cpu().numpy())\n",
    "    \n",
    "        test_targets = np.concatenate(test_targets)\n",
    "        test_preds = np.concatenate(test_preds)\n",
    "        test_r2 = r2_score(test_targets, test_preds)\n",
    "        original_r2_scores.append(test_r2)\n",
    "\n",
    "        rewired_test_preds, rewired_test_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in rewired_test_loader:\n",
    "                batch = batch.to(device)\n",
    "                batch.x = batch.x.float()\n",
    "                batch.y = batch.y.float().view(-1, 1)\n",
    "                out = model(batch)\n",
    "                rewired_test_preds.append(batch.y.cpu().numpy())\n",
    "                rewired_test_targets.append(out.cpu().numpy())\n",
    "\n",
    "        rewired_test_preds = np.concatenate(rewired_test_preds)\n",
    "        rewired_test_targets = np.concatenate(rewired_test_targets)\n",
    "        rewired_test_r2 = r2_score(rewired_test_targets, rewired_test_preds)\n",
    "        rewired_r2_scores.append(rewired_test_r2)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Original Test R2: {test_r2:.4f}, Rewired Test R2: {rewired_test_r2:.4f}')\n",
    "\n",
    "    \n",
    "    return train_losses, original_r2_scores, rewired_r2_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes=1, hidden_dim=64, depth=3):\n",
    "        super(GINModel, self).__init__()\n",
    "\n",
    "        # Define GIN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GINConv(\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Linear(num_features, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.ReLU()\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        # Additional GIN layers\n",
    "        for _ in range(depth - 1):\n",
    "            self.convs.append(GINConv(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                    torch.nn.ReLU()\n",
    "                )\n",
    "            ))\n",
    "\n",
    "        # Batch normalization layers\n",
    "        self.batch_norms = torch.nn.ModuleList([BatchNorm(hidden_dim) for _ in range(depth)])\n",
    "\n",
    "        # Final regression layer\n",
    "        self.final_lin = torch.nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for conv, batch_norm in zip(self.convs, self.batch_norms):\n",
    "            x = conv(x, edge_index)\n",
    "            x = batch_norm(x)\n",
    "            x = F.relu(x)\n",
    "        x = global_add_pool(x, data.batch)  # Pool to get a graph-level representation\n",
    "        x = self.final_lin(x)  # Final regression output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=GINModel(num_features=dataset[0].x.shape[1])\n",
    "r2_values = train_test_model(model, dataset, num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewiring started\n",
      "Rewiring ended\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import inf\n",
    "\n",
    "def choose_edge_to_add(x, edge_index, degrees):\n",
    "    # chooses edge (u, v) to add which minimizes y[u]*y[v]\n",
    "    n = x.size\n",
    "    m = edge_index.shape[1]\n",
    "    y = x / ((degrees + 1) ** 0.5)\n",
    "    products = np.outer(y, y)\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        products[u, v] = inf\n",
    "    for i in range(n):\n",
    "        products[i, i] = inf\n",
    "    smallest_product = np.argmin(products)\n",
    "    return (smallest_product % n, smallest_product // n)\n",
    "\n",
    "def compute_degrees(edge_index, num_nodes=None):\n",
    "    # returns array of degrees of all nodes\n",
    "    if num_nodes is None:\n",
    "        num_nodes = np.max(edge_index) + 1\n",
    "    degrees = np.zeros(num_nodes)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        degrees[edge_index[0, i]] += 1\n",
    "    return degrees\n",
    "\n",
    "def add_edge(edge_index, u, v):\n",
    "    new_edge = np.array([[u, v],[v, u]])\n",
    "    return np.concatenate((edge_index, new_edge), axis=1)\n",
    "\n",
    "def adj_matrix_multiply(edge_index, x):\n",
    "    # given an edge_index, computes Ax, where A is the corresponding adjacency matrix\n",
    "    n = x.size\n",
    "    y = np.zeros(n)\n",
    "    m = edge_index.shape[1]\n",
    "    for i in range(m):\n",
    "        u = edge_index[0, i]\n",
    "        v = edge_index[1, i]\n",
    "        y[u] += x[v]\n",
    "    return y\n",
    "\n",
    "def compute_spectral_gap(edge_index, x):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\ty = adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\tfor i in range(n):\n",
    "\t\tif x[i] > 1e-9:\n",
    "\t\t\treturn 1 - y[i]/x[i]\n",
    "\treturn 0.\n",
    "\n",
    "def _edge_rewire(edge_index, edge_type, x=None, num_iterations=50, initial_power_iters=50):\n",
    "\tm = edge_index.shape[1]\n",
    "\tn = np.max(edge_index) + 1\n",
    "\tif x is None:\n",
    "\t\tx = 2 * np.random.random(n) - 1\n",
    "\tdegrees = compute_degrees(edge_index, num_nodes=n)\n",
    "\tfor i in range(initial_power_iters):\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\tfor I in range(num_iterations):\n",
    "\t\ti, j = choose_edge_to_add(x, edge_index, degrees=degrees)\n",
    "\t\tedge_index = add_edge(edge_index, i, j)\n",
    "\t\tdegrees[i] += 1\n",
    "\t\tdegrees[j] += 1\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tedge_type = np.append(edge_type, 1)\n",
    "\t\tx = x - x.dot(degrees ** 0.5) * (degrees ** 0.5)/sum(degrees)\n",
    "\t\ty = x + adj_matrix_multiply(edge_index, x / (degrees ** 0.5)) / (degrees ** 0.5)\n",
    "\t\tx = y / np.linalg.norm(y)\n",
    "\treturn edge_index, edge_type, x\n",
    "\n",
    "def edge_rewire(edge_index, x=None, edge_type=None, num_iterations=50, initial_power_iters=5):\n",
    "    m = edge_index.shape[1]\n",
    "    n = np.max(edge_index) + 1\n",
    "    if x is None:\n",
    "        x = 2 * np.random.random(n) - 1\n",
    "    if edge_type is None:\n",
    "        edge_type = np.zeros(m, dtype=np.int64)\n",
    "    return _edge_rewire(edge_index, edge_type=edge_type, x=x, num_iterations=num_iterations, initial_power_iters=initial_power_iters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "fosr_dataset=dataset.copy()\n",
    "\n",
    "print(\"Rewiring started\")\n",
    "for i in range(len(dataset)):\n",
    "    \n",
    "    edge_index, edge_type, _ = edge_rewire(dataset[i].edge_index.numpy(), num_iterations=2)\n",
    "    fosr_dataset[i].edge_index = torch.tensor(edge_index)\n",
    "    fosr_dataset[i].edge_type = torch.tensor(edge_type)\n",
    "print(\"Rewiring ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=GINModel(num_features=dataset[0].x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:46<02:18, 46.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Train Loss: 69.6996, Original Test R2: 0.0726, Rewired Test R2: 0.3589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [01:22<01:20, 40.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4, Train Loss: 55.5451, Original Test R2: 0.5211, Rewired Test R2: -0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:58<00:38, 38.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4, Train Loss: 50.8030, Original Test R2: 0.6545, Rewired Test R2: 0.5219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:42<00:00, 40.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4, Train Loss: 48.0309, Original Test R2: 0.4309, Rewired Test R2: 0.5242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, original_r2_scores, rewired_r2_scores = train_test_model(model, dataset, fosr_dataset, num_epochs=4, batch_size=32, learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
